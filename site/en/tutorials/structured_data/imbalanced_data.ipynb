{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dUeKVCYTbcyT"
      },
      "source": [
        "#### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "4ellrPx7tdxq"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JfLUlawto_D"
      },
      "source": [
        "# Classification on imbalanced data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DwdpaTKJOoPu"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/imbalanced_data.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mthoSGBAOoX-"
      },
      "source": [
        "This tutorial demonstrates how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another. You will work with the [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) dataset hosted on Kaggle. The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. You will use [Keras](../../guide/keras/overview.ipynb) to define the model and [class weights](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model) to help the model learn from the imbalanced data. You will display metrics for precision, recall, true positives, false positives, true negatives, false negatives, and AUC while training the model. These are more informative than accuracy when working with imbalanced datasets classification.\n",
        "\n",
        "This tutorial contains complete code to:\n",
        "\n",
        "* Load a CSV file using Pandas.\n",
        "* Create train, validation, and test sets.\n",
        "* Define and train a model using Keras (including setting class weights).\n",
        "* Evaluate the model using various metrics (including precision and recall)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kRHmSyHxEIhN"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yJHVo_K_v20i"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fYBlUQ5FvzxP"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jZk7QMofhnk_"
      },
      "outputs": [],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JM7hDSNClfoK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4sA9WOcmzH2D"
      },
      "source": [
        "## Use Pandas to get the Kaggle Credit Card Fraud data set\n",
        "\n",
        "Pandas is a Python library with many helpful utilities for loading and working with structured data and can be used to download CSVs into a dataframe.\n",
        "\n",
        "Note: This dataset has been collected and analysed during a research collaboration of Worldline and the [Machine Learning Group](http://mlg.ulb.ac.be) of ULB (Universit√© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available [here](https://www.researchgate.net/project/Fraud-detection-5) and the page of the [DefeatFraud](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pR_SnbMArXr7"
      },
      "outputs": [],
      "source": [
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6qox6ryyzwdr"
      },
      "source": [
        "## Split the dataframe into train, validation, and test\n",
        "\n",
        "Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where [overfitting](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting) is a significant concern from the lack of training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IO-qEUmJ5JQg"
      },
      "outputs": [],
      "source": [
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(raw_df, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "val_labels = np.array(val_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)\n",
        "\n",
        "# Normalize the input features using the sklearn StandardScaler.\n",
        "# This will set the mean to 0 and standard deviation to 1.\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Validation labels shape:', val_labels.shape)\n",
        "print('Test labels shape:', test_labels.shape)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Validation features shape:', val_features.shape)\n",
        "print('Test features shape:', test_features.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xWKB_CVZFLpB"
      },
      "source": [
        "## Examine the class label imbalance\n",
        "\n",
        "Let's look at the dataset imbalance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HCJFrtuY2iLF"
      },
      "outputs": [],
      "source": [
        "neg, pos = np.bincount(train_labels)\n",
        "total = neg + pos\n",
        "print('{} positive samples out of {} training samples ({:.2f}% of total)'.format(\n",
        "    pos, total, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KnLKFQDsCBUg"
      },
      "source": [
        "This shows a small fraction of positive samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qFK1u4JX16D8"
      },
      "source": [
        "## Define the model and metrics\n",
        "\n",
        "Define a function that creates a simple neural network with three densely connected hidden layers, an output sigmoid layer that returns the probability of a transaction being fraudulent, and two [dropout](https://developers.google.com/machine-learning/glossary/#dropout_regularization) layers as an effective way to reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3JQDzUqT3UYG"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(256, activation='relu',\n",
        "                         input_shape=(train_features.shape[-1],)),\n",
        "      keras.layers.Dense(256, activation='relu'),\n",
        "      keras.layers.Dropout(0.3),\n",
        "      keras.layers.Dense(256, activation='relu'),\n",
        "      keras.layers.Dropout(0.3),\n",
        "      keras.layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "\n",
        "  metrics = [\n",
        "      keras.metrics.Accuracy(name='accuracy'),\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc')\n",
        "  ]\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=metrics)\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SU0GX6E6mieP"
      },
      "source": [
        "## Understanding useful metrics\n",
        "\n",
        "Notice that there are a few metrics defined above that can be computed by the model that will be helpful when evaluating the performance.\n",
        "\n",
        "\n",
        "\n",
        "*   **False** negatives and **false** positives are samples that were **incorrectly** classified\n",
        "*   **True** negatives and **true** positives are samples that were **correctly** classified\n",
        "*   **Accuracy** is the percentage of examples correctly classified\n",
        "\u003e   $\\frac{\\text{true samples}}{\\text{total samples}}$\n",
        "*   **Precision** is the percentage of **predicted** positives that were correctly classified\n",
        "\u003e   $\\frac{\\text{true positives}}{\\text{true positives + false positives}}$\n",
        "*   **Recall** is the percentage of **actual** positives that were correctly classified\n",
        "\u003e   $\\frac{\\text{true positives}}{\\text{true positives + false negatives}}$\n",
        "*   **AUC** refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than than a random negative sample.\n",
        "\n",
        "\u003cbr\u003e\n",
        "\n",
        "Read more:\n",
        "*  [True vs. False and Positive vs. Negative](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)\n",
        "*  [Accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
        "*   [Precision and Recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\n",
        "*   [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IDbltVPg2m2q"
      },
      "source": [
        "## Train a baseline model\n",
        "\n",
        "Now create and train your model using the function that was defined earlier. Notice that the model is fit using a larger than default batch size of 2048, this is important to ensure that each batch has a decent chance of containing a few positive samples. If the batch size was too small, they would likely have no fraudelent transactions to learn from.\n",
        "\n",
        "\n",
        "Note: this model will not handle the class imbalance well. You will improve it later in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yZKAc8NCDnoR"
      },
      "outputs": [],
      "source": [
        "model = make_model()\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iSaDBYU9xtP6"
      },
      "source": [
        "## Plot metrics on the training and validation sets\n",
        "In this section, you will produce plots of your model's accuracy and loss on the training and validation set. These are useful to check for overfitting, which you can learn more about in this [tutorial](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
        "\n",
        "Additionally, you can produce these plots for any of the metrics you created above. False negatives are included as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WTSkhT1jyGu6"
      },
      "outputs": [],
      "source": [
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(epochs,  history.history['accuracy'], color='blue', label='Train')\n",
        "plt.plot(epochs, history.history['val_accuracy'], color='orange', label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "_ = plt.figure()\n",
        "plt.title('Loss')\n",
        "plt.plot(epochs, history.history['loss'], color='blue', label='Train')\n",
        "plt.plot(epochs, history.history['val_loss'], color='orange', label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "_ = plt.figure()\n",
        "plt.title('False Negatives')\n",
        "plt.plot(epochs, history.history['fn'], color='blue', label='Train')\n",
        "plt.plot(epochs, history.history['val_fn'], color='orange', label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('False Negatives')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oyOhKsc0yYxg"
      },
      "source": [
        "## Evaluate the baseline model\n",
        "\n",
        "Evaluate your model on the test dataset and display results for the metrics you created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rPfIaXn3Jr6B"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_features, test_labels)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(name, ': ', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gpdsFyp64DhY"
      },
      "source": [
        "It looks like the precision is relatively high, but the recall and AUC aren't as high as you might like. Classifiers often face challenges when trying to maximize both precision and recall, which is especially true when working with imbalanced datasets. However, because missing fraudulent transactions (false negatives) may have significantly worse business consequences than incorrectly flagging fraudulent transactions (false positives), recall may be more important than precision in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aJC1booryouo"
      },
      "source": [
        "## Examine the confusion matrix\n",
        "\n",
        "You can use a [confusion matrix](https://developers.google.com/machine-learning/glossary/#confusion_matrix) to summarize the actual vs. predicted labels where the X axis is the predicted label and the Y axis is the actual label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "poh_hZngt2_9"
      },
      "outputs": [],
      "source": [
        "predicted_labels = model.predict(test_features)\n",
        "cm = confusion_matrix(test_labels, np.round(predicted_labels))\n",
        "\n",
        "plt.matshow(cm, alpha=0)\n",
        "plt.title('Confusion matrix')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "for (i, j), z in np.ndenumerate(cm):\n",
        "    plt.text(j, i, str(z), ha='center', va='center')\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PyZtSr1v6L4t"
      },
      "source": [
        "If the model had predicted everything perfectly, this would be a [diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix) where values off the main diagonal, indicating incorrect predictions, would be zero. In this case the matrix shows that you have relatively few false positives, meaning that there were relatively few legitimate transactions that were incorrectly flagged. However, you would likely want to have even fewer false negatives despite the cost of increasing the number of false positives. This trade off may be preferable because false negatives would allow fraudulent transactions to go through, whereas false positives may cause an email to be sent to a customer to ask them to verify their card activity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ePGp6GUE1WfH"
      },
      "source": [
        "## Using class weights for the loss function\n",
        "\n",
        "The goal is to identify fradulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qjGWErngGny7"
      },
      "outputs": [],
      "source": [
        "\n",
        "weight_for_0 = 1 / neg\n",
        "weight_for_1 = 1 / pos\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2e}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2e}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mk1OOE2ZSHzy"
      },
      "source": [
        "## Train a model with class weights\n",
        "\n",
        "Now try re-training and evaluating the model with class weights to see how that affects the predictions.\n",
        "\n",
        "Note: Using `class_weights` changes the range of the loss. This may affect the stability of the training depending on the optimizer. Optimizers who's step size is dependent on the magnitude of the gradient, like `optimizers.SGD`, may fail. The optimizer used here, `optimizers.Adam`, is unaffected by the scaling change. Also note that because of the weighting, the total losses are not comparable between the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UJ589fn8ST3x"
      },
      "outputs": [],
      "source": [
        "weighted_model = make_model()\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "owKL2vdMBJr6"
      },
      "outputs": [],
      "source": [
        "weighted_results = weighted_model.evaluate(test_features, test_labels)\n",
        "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
        "  print(name, ': ', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PTh1rtDn8r4-"
      },
      "source": [
        "Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives. Despite having lower overall accuracy, this approach may be better when considering the consequences of failing to identify fraudulent transactions driving the prioritization of recall. Depending on how bad false negatives are, you might use even more exaggerated weights to further improve recall while dropping precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "18VUHNc-UF5w"
      },
      "source": [
        "## Oversampling the minority class\n",
        "\n",
        "A related approach would be to resample the dataset by oversampling the minority class, which is the process of creating more positive samples using something like sklearn's [imbalanced-learn library](https://github.com/scikit-learn-contrib/imbalanced-learn). This library provides methods to create new positive samples by simply duplicating random existing samples, or by interpolating between them to generate synthetic samples using variations of [SMOTE](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#Oversampling_techniques_for_classification_problems). TensorFlow also provides a way to do [Random Oversampling](https://www.tensorflow.org/api_docs/python/tf/data/experimental/sample_from_datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jOlgyG1D6kCU"
      },
      "outputs": [],
      "source": [
        "# with default args this will oversample the minority class to have an equal\n",
        "# number of observations\n",
        "smote = SMOTE()\n",
        "res_features, res_labels = smote.fit_sample(train_features, train_labels)\n",
        "\n",
        "res_neg, res_pos = np.bincount(res_labels)\n",
        "res_total = res_neg + res_pos\n",
        "print('{} positive samples out of {} training samples ({:.2f}% of total)'.format(\n",
        "    res_pos, res_total, 100 * res_pos / res_total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XZ1BvEpcBVHP"
      },
      "source": [
        "## Train and evaluate a model on the resampled data\n",
        "\n",
        "Now try training the model with the resampled data set instead of using class weights to see how these methods compare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7Hz_-DuLA6Yd"
      },
      "outputs": [],
      "source": [
        "resampled_model = make_model()\n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    res_features,\n",
        "    res_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FO0mMOYUDWFk"
      },
      "outputs": [],
      "source": [
        "resampled_results = resampled_model.evaluate(test_features, test_labels)\n",
        "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
        "  print(name, ': ', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w3CDoej5GOui"
      },
      "source": [
        "This approach can be worth trying, but may not provide better results than using class weights because the synthetic examples may not accurately represent the underlying data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3o3f0ywl8uqW"
      },
      "source": [
        "## Applying this tutorial to your problem\n",
        "\n",
        "Imbalanced data classification is an inherantly difficult task since there are so few samples to learn from. You should always start with the data first and do your best to collect as many samples as possible and give substantial thought to what features may be relevant so the model can get the most out of your minority class. At some point your model may struggle to improve and yield the results you want, so it is important to keep in mind the context of the problem to evaluate how bad your false positives or negatives really are."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "imbalanced_data.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
